---
title: "Climate Change Awareness: A Eurobarometer Survey Harmonization Case Study"
author: "Daniel Antal, CFA"
date: "3/4/2021"
output: md_document
---

Retrospective survey harmonization comes with many challenges, as we have shown in the [introduction](http://netzero.dataobservatory.eu/post/2021-03-04_retroharmonize_intro/) to this tutorial case study. In this example, we will work with Eurobarometerâ€™s data. 

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Please use the development version of [retroharmonize](https://retroharmonize.dataobservatory.eu/):

```{r install-retroharmonize, eval=FALSE}
devtools::install_github("antaldaniel/retroharmonize")
```

```{r load-pkg, message=FALSE}
library(retroharmonize)
library(dplyr)       # this is necessary for the example 
library(lubridate)   # easier date conversion
library(stringr)     # You can also use base R string processing functions 
```

## Get the Data

`retroharmonize` is not associated with Eurobarometer, its creators (Kantar), or its archivists (GESIS). We assume that you have acquired the necessary files from GESIS after carefully reading their terms and that you have placed them on a path that you call gesis_dir. The precise documentation of the data we use can be found in this supporting [blogpost](http://netzero.dataobservatory.eu/post/2021-03-04-eurobarometer_data/). To reproduce this blogpost, you will need `ZA5877_v2-0-0.sav`, `ZA6595_v3-0-0.sav`,  `ZA6861_v1-2-0.sav`, `ZA7488_v1-0-0.sav`, `ZA7572_v1-0-0.sav` in a directory that you have named `gesis_dir`.

```{r read-files, eval=FALSE}
#Not run in the blogpost. In the repo we have a saved version.
climate_change_files <- c("ZA5877_v2-0-0.sav", "ZA6595_v3-0-0.sav",  "ZA6861_v1-2-0.sav", 
                          "ZA7488_v1-0-0.sav", "ZA7572_v1-0-0.sav")

eb_waves <- read_surveys(file.path(gesis_dir, climate_change_files), .f='read_spss')

if (dir.exists("data-raw")) {
  save ( eb_waves,  file = file.path("data-raw", "eb_climate_change_waves.rda") )
}
```

```{r load-existing-data}
if ( file.exists( file.path("data-raw", "eb_climate_change_waves.rda") )) {
  load (file.path( "data-raw", "eb_climate_change_waves.rda" ) )
} else {
  load (file.path("..", "..",  "data-raw", "eb_climate_change_waves.rda") )
}
```

The `eb_waves` nested list contains five surveys imported from SPSS to the survey class of [retroharmonize](https://retroharmonize.dataobservatory.eu/articles/labelled_spss_survey.html). The survey class is a data.frame that retains important metadata for further harmonization.

```{r wave-contents}
document_waves (eb_waves)
```

Beware of the object sizes. If you work with many surveys, memory-efficient programming becomes imperative. We will be subsetting whenever possible.

## Metadata analysis

As noted before, be prepared to work with nested lists. Each imported survey is nested as a data frame in the `eb_waves` list. 

```{r metadata, echo=FALSE, messag=FALSE, warning=FALSE}
eb_climate_metadata <- lapply ( X = eb_waves, FUN = metadata_create )
eb_climate_metadata <- do.call(rbind, eb_climate_metadata)
```

## Metadata: Protocol Variables

Eurobarometer refers to certain metadata elements, like interviewee cooperation level or the date of a survey interview as protocol variables. Let's start here. This will be our template to harmonize more and more aspects of the five surveys (which are, in fact, already harmonizations of about 30 surveys conducted in a single 'wave' in multiple countries.)

```{r metadata-protocol}
# select variables of interest from the metadata
eb_protocol_metadata <- eb_climate_metadata %>%
  filter ( .data$label_orig %in% c("date of interview") |
             .data$var_name_orig == "rowid")  %>%
  suggest_var_names( survey_program = "eurobarometer" )

# subset and harmonize these variables in all nested list items of 'waves' of surveys
interview_dates <- harmonize_var_names(eb_waves, 
                                       eb_protocol_metadata )

# apply similar data processing rules to same variables
interview_dates <- lapply (interview_dates, 
                      function (x) x %>% mutate ( date_of_interview = as_character(.data$date_of_interview) )
                      )

# join the individual survey tables into a single table 
interview_dates <- as_tibble ( Reduce (rbind, interview_dates) )

# Check the variable classes.

vapply(interview_dates, function(x) class(x)[1], character(1))
```

This is our sample workflow for each block of variables.  

1. Get a unique identifier. 
2. Add other variables. 
3. Harmonize the variable names.
4. Subset the data, leaving out anything that you do not harmonize in this block.  
5. Apply some normalization in a nested list.
6. When the variables are harmonized to have the same names and class, merge them into a data.frame-like `tibble` object.

Now finish the harmonization. `Wednesday, 31st October 2018` should become a Date type `2018-10-31`.

```{r protocol, message=FALSE}
require(lubridate)
harmonize_date <- function(x) {
  x <- tolower(as.character(x))
  x <- gsub("monday|tuesday|wednesday|thursday|friday|saturday|sunday|\\,|th|nd|rd|st", "", x)
  x <- gsub("decemberber", "december", x) # all those annoying real-life data problems!
  x <- stringr::str_trim (x, "both")
  x <- gsub("^0", "", x )
  x <- gsub("\\s\\s", "\\s", x)
  lubridate::dmy(x) 
}

interview_dates <- interview_dates %>%
  mutate ( date_of_interview = harmonize_date(.data$date_of_interview) )

vapply(interview_dates, function(x) class(x)[1], character(1))
```

To avoid duplication of row IDs in surveys that may not be unique in _different_ surveys, we created a simple, sequential ID for each survey, including the ID of the original file.

```{r sample-dates}
set.seed(2021)
sample_n(interview_dates, 6)
```


After this type-conversion problem let's see an issue when an original SPSS variable can have two meaningful R representations.

## Metadata: Geographical information 

Let's continue with harmonizing geographical information in the files. In this example, `var_name_suggested` will contain the harmonized variable name. It is likely that you will have to make this call after carefully reading the original questionnaires and codebooks.

```{r regmetadata}
eb_regional_metadata <- eb_climate_metadata %>%
  filter ( grepl( "rowid|isocntry|^nuts$", .data$var_name_orig)) %>%
  suggest_var_names( survey_program = "eurobarometer" ) %>%
  mutate ( var_name_suggested = case_when ( 
    var_name_suggested == "region_nuts_codes"     ~ "geo",
    TRUE ~ var_name_suggested ))

```

`harmonize_var_names()` takes all variables in the subsetted, geographical metadata table, and brings them to the harmonized `var_name_suggested` name. The function subsets the surveys to avoid the presence of non-harmonized variables. All regional NUTS codes become `geo` in our case:

```{r harmonize-geography-vars}
geography <- harmonize_var_names(eb_waves, 
                                 eb_regional_metadata)
```

If you are used to working with single survey files, you are likely to work in a tabular format, which easily converts into a data.frame-like object. In our example, we use tidyverse's `tibble`. However, when working with longitudinal data, it is far simpler to work with nested lists, because tables usually have different dimensions (neither the rows corresponding to observations or the columns are the same across all survey files).

In the nested list, each list element is a single, tabular-format survey. In fact, the surveys are in retroharmonize's [survey](https://retroharmonize.dataobservatory.eu/reference/survey.html) class, which is a rich tibble that contains the metadata and the processing history of the survey.

The regional information in the Eurobarometer files is contained in the `nuts` variable.  We want to keep both the original labels and values. The original values are the region's codes, and the labels are the names. The easiest and fastest solution is the base R `lapply` loop.

```{r process-geography-vars}
geography <- lapply ( geography, 
                      function (x) x %>% mutate ( region = as_character(geo), 
                                                  geo    = as.character(geo) )  
)

```

Because each table has exactly the same columns, we can simply use `rbind()` and reduce the list to a modern `data.frame`, i.e. a `tibble`. 

```{r join-geography-vars }
geography <- as_tibble ( Reduce (rbind, geography) )
```

Let's see a dozen cases: 

```{r check-geography-vars}
set.seed(2021)
sample_n(geography, 12)
```

The idea is that we do similar variable harmonization block by block, and eventually we will join them together.  Next step: socio-demography and weights.

## Socio-demography and Weights

There are a few peculiar issues to look out for. This example shows that survey harmonization requires plenty of expert judgment, and you cannot fully automate the process. 

The Eurobarometer archives do not use all weight and demographic variable names consistently. For example, the `wex` variable, which is a projected weight for the country's 15 years old or older population is sometimes called `wex`, sometimes `wextra`. The individual survey's post-stratification weight is the `w1` variable, but this is not necessarily what you need to use. 

The `suggest_var_names()` function has a parameter for `survey_program = "eurobaromater"` which normalizes, to some extent, the most used variables. For example, all variations of wex and wextra will be normalized to wex. You can ignore this parameter and use your own names, too. 

```{r demography-metadata}
eb_demography_metadata  <- eb_climate_metadata %>%
  filter ( grepl( "rowid|isocntry|^d8$|^d7$|^wex|^w1$|d25|^d15a|^d11$", .data$var_name_orig) ) %>%
  suggest_var_names( survey_program = "eurobarometer")
```

As you can see, using the original labels would not help, because they also contain various alterations.

```{r subset-demography}
eb_demography_metadata %>%
  select ( filename, var_name_orig, label_orig, var_name_suggested ) %>%
  filter (var_name_orig %in% c("wex", "wextra") )
```
```{r harmonize-demography-vars}
demography <- harmonize_var_names ( waves = eb_waves, 
                                    metadata = eb_demography_metadata ) 
```

Socio-demographic variables like level of highest education or occupation are rather country-specific. Eurobarometer uses standardized occupation and marital status scales, and a proxy for education levels and the age of leaving full-time education. 

This is a particularly tricky variable, because its coding in fact contains three different variables - school leaving age, except for students, and except for people who did not finish their compulsory primary school. And while school leaving age was a good proxy starting in the 1970s, in an age when the EU is promoting life-long-learning it becomes less and less useful, as people stop and re-start their education throughout their lives.

```{r age-education}
example <- demography[[1]] %>%
  mutate ( across ( -any_of(c("rowid", "w1", "wex")), as_character) ) %>%
  mutate ( across (any_of(c("w1", "wex")), as_numeric) )
unique ( example$age_education )
```

The seemingly trival `age_exact` variable has its own issues, too:

```{r age}
unique ( example$age_exact)
```

Let's see all the strange labels attached to `age`-type variables:

```{r collect-val}
collect_val_labels(metadata = eb_demography_metadata %>%
                     filter ( var_name_suggested %in% c("age_exact", "age_education")) )
```

We must handle many exceptions, so we created a function for this purpose:

```{r harmonize-demography}
remove_years  <- function(x) { 
  x <- gsub("years|and\\solder", "", tolower(x))
  stringr::str_trim (x, "both")}

process_demography <- function (x) { 
  
  x %>% mutate ( across ( -any_of(c("rowid", "w1", "wex")), as_character) ) %>%
    mutate ( across (any_of(c("w1", "wex")), as_numeric) ) %>%
    mutate ( across (contains("age"), remove_years)) %>%
    mutate ( age_exact = as.numeric (age_exact)) %>%
    mutate ( is_student = ifelse ( tolower(age_education) == "still studying", 
                                   1, 0), 
             no_education = ifelse ( tolower(age_education) == "no full-time education", 1, 0)) %>%
    mutate ( education = case_when (
      grepl("studying", age_education) ~ age_exact, 
      grepl ("education", age_education)  ~ 14, 
      grepl ("refus|document|dk", tolower(age_education)) ~ NA_real_,
      TRUE ~ as.numeric(age_education)
    ))  %>%
    mutate ( education = case_when ( 
      education < 14 ~ NA_real_, 
      education > 30 ~ 30, 
      TRUE ~ education )) 
}

demography <- lapply ( demography, process_demography )

## WE'll full join and not use rbind, because we have different variables in different waves.
demography <- Reduce ( full_join, demography )
```

Now let's see what we have here:

```{r sample-demography}
set.seed(2021)
sample_n(demography, 12)
```

## Harmonizing Variable Labels

So far we have been working with metadata, weights and socio-demography. In other words, we have not even started the desired harmonization of climate change awareness.  The methodology is the same, but here we really must look out for the answer options in the questionnaire. (Refer to our data summary again [here](http://netzero.dataobservatory.eu/post/2021-03-04-eurobarometer_data/).)

```{r subset-climate-waves}
climate_awareness_metadata <- eb_climate_metadata %>%
  suggest_var_names( survey_program = "eurobarometer" ) %>%
  filter ( .data$var_name_suggested  %in% c("rowid",
                                            "serious_world_problems_first", 
                                             "serious_world_problems_climate_change")
  ) 
```

```{r harmonize-climate-data}
hw <- harmonize_var_names ( waves = eb_waves, 
                            metadata = climate_awareness_metadata )
```

The `retroharmonize` package comes with a generic [harmonize_values()](https://retroharmonize.dataobservatory.eu/reference/harmonize_waves.html) function that will change the value labels of categorical variables (including binary ones) to a unitary format. It will also take care of various types of missing values.

First, let's go back to our metadata and collect all value labels that will show up with [collect_val_labels()](https://retroharmonize.dataobservatory.eu/reference/collect_val_labels.html):

```{r climate-labels}
collect_val_labels(climate_awareness_metadata)
```

In this case, we want to select `Climate change` as the mentioned _most serious problem_, and `Climate change` taken from a list of three serious problems. The first question type is a single-choice one, where `Climate change` is either mentioned, or the alternative answer is labeled as `Not mentioned`. In the multiple choice case, the alternative may be something else, for example, `Spread of infectious diseases`, as we all well know by 2021.

We want to see who thought `Climate change` was the most serious problem, or one of the most serious problems, so we label each mentions of `Climate change` as `mentioned` and we pair it with a numeric value of `1`.  All other cases are labeled as `not_mentioned`, with the exceptions of various missing observations, which in these cases are `Do not know` answers, `Declined to answer` cases, and `Inappropriate` cases [The latter one is Eurobarometer's label for questions that were for one reason or other not asked from a particular interviewee -- for example, because the Turkish Cypriot community received a different questionnaire.]

```{r labelling-climate-1}
# positive cases
label_1 = c("^Climate\\schange", "^Mentioned")
# missing cases 
na_labels <- collect_na_labels( climate_awareness_metadata)
na_labels
```

```{r labelling-climate-0}
# negative cases
label_0 <- collect_val_labels( climate_awareness_metadata)
label_0 <- label_0[! label_0 %in% label_1 ]
```

The `harmonize_serious_problems()` function harmonizes the labels within the special labeled class of `retroharmonize`.  This class retains all information to give categorical variables a character or numeric representation, and various processing metadata for documentation purposes. While this class is very rich (it contains whatever was imported from SPSS's proprietary data format and history), it is not suitable for statistical analysis. We could, of course, directly call [harmonize_values()](https://retroharmonize.dataobservatory.eu/reference/harmonize_values.html) from the retroharmonize package, but the parametrization would be very complicated even in a simple function call, not to mention a looped call. Because this function is the heart of the `retroharmonize package`, it has [a tutorial article](https://retroharmonize.dataobservatory.eu/articles/harmonize_labels.html) of its own.

```{r adopt-harmonization function}
harmonize_serious_problems <- function(x) {
  label_list <- list(
    from = c(label_0, label_1, na_labels), 
    to = c( rep ( "not_mentioned", length(label_0) ),   # use the same order as in from!
            rep ( "mentioned", length(label_1) ),
            "do_not_know", "inap", "inap", "inap"), 
    numeric_values = c(rep ( 0, length(label_0) ), # use the same order as in from!
                       rep ( 1, length(label_1) ),
                       99997,99999,99999,99999)
  )
  
  harmonize_values(x, 
                   harmonize_labels = label_list, 
                   na_values = c("do_not_know"=99997,
                                 "declined"=99998,
                                 "inap"=99999), 
                   remove = "\\(|\\)|\\[|\\]|\\%"
  )
}
```

Our objects are rather big in memory, so first, let's remove the surveys that do not contain these world problem variables. In this cases, the subsetted and harmonized surveys in the nested list have only one columns, i.e. the `rowid`. 

```{r remove-empty}
hw <- hw[unlist ( lapply ( hw, ncol)) > 1 ]
```

Now we have a smaller problem to deal with. With the processing of multiple surveys it is easy to exhaust your computer's memory, so let's start building up our joined panel data from a smaller set of nested, subsetted surveys.

```{r harmonized-waves}
hw <- lapply ( hw, function (x) x %>% mutate ( across ( contains("problem"), harmonize_serious_problems) ) )
```

Our `lapply` loop calls an anonymous function which in turn calls the `harmonize_serious_problems` parametrized version of the [harmonize_values()](https://retroharmonize.dataobservatory.eu/reference/harmonize_values.html) on all variables that have `problem` in their names.

Once we are done, our variables have harmonized names, harmonized values, and harmonized labels, but they are stored in the complex [retroharmonize_labelled_spss_survey](https://retroharmonize.dataobservatory.eu/articles/harmonize_labels.html) class, inherited from the `haven_labelled_spss` class in [haven](https://haven.tidyverse.org/).

We reduced our single and multiple choice questions to binary choice variables. We can now give them a numeric representation. Be mindful that `retroharmonize` has special methods for its special labeled class that retains metadata from SPSS. This means that `as_character` and `as_numeric` knows how to handle various types of missing values, whereas the base R `as.character` and `as.numeric` may coerce special values to unwanted results. This is particularly dangerous with numeric variables -- and this is the reason why we introduced a new set of S3 objects and methods in the package.

We will ignore the differences between various forms of missingness, i.e. the person said that they did not know, or did not want to answer, or for some reason was not asked in the survey. In a more descriptive, non-harmonized analysis you would probably want to explore them as various 'categories' and use a character representation. 

```{r join-waves, message=FALSE}
hw <- lapply ( hw, function(x) x %>% mutate ( across ( contains("problem"), as_numeric) ))

hw <- Reduce ( full_join, hw) # we must use joins instead of binds because the number of columns vary.
```

Let's see what we have: 

```{r joined-wave-sample}
set.seed(2021)
sample_n (hw, 12)
```

## Creating the Longitudional Table

Now we just need to join the partial table by the `rowid` together:

```{r join-all-up, message=FALSE}
#start from the smallest (we removed the survey that had no relevant questionnaire item)
panel <- hw %>%
  left_join ( geography, by = 'rowid' ) 

panel <- panel %>%
  left_join ( demography, by = c("rowid", "isocntry") ) 

panel <- panel %>%
  left_join ( interview_dates, by = 'rowid' )
```

And let's see a small sample: 

```{r}
sample_n(panel, 12)
```

```{r save-to-tempdir}
saveRDS ( panel, file.path(tempdir(), "climate_panel.rds"), version = 2)
```

```{r copy-file, eval=TRUE}
# not evaluated
saveRDS( panel, file = file.path("data-raw", "climate-panel.rds"), version=2)
```

## Putting It on a Map

This is not the end of the story. If you put all this on a map, the results are a bit disappointing. 

```{r wrong-map, message=FALSE, warning=FALSE, echo=FALSE}
if (file.exists("nuts2_2016.png")) {
  knitr::include_graphics("nuts2_2016.png")
} else {
  knitr::include_graphics(file.path("plots", "nuts2_2016.png"))
}

```

Why? Because sub-national (provincial, state, county, district, parish) borders are changing all the time - within the EU and everywhere. The next step is to harmonize the geographical information. We have another CRAN released package to help you with this. See the next post: [Regional Climate Change Awareness Dataset](https://rpubs.com/antaldaniel/regions-OOD21).